"""
General Information Expert - Handles general Q&A about destinations
"""

import logging
import time
from typing import Dict, Any, List
from .base_expert import BaseExpert, ExpertResult
from app.services.entity_extractor import create_entity_extractor, ExtractedEntity

logger = logging.getLogger("travel-advisor")


class GeneralInfoExpert(BaseExpert):
    """
    Expert for handling general information queries about destinations
    Uses LLM to provide contextual answers based on destination data
    """

    TRAVEL_TIPS = {
        "thanh-hoa": {
            "weather": "Thanh H√≥a c√≥ kh√≠ h·∫≠u nhi·ªát ƒë·ªõi gi√≥ m√πa. M√πa kh√¥ t·ª´ th√°ng 11-4, m√πa m∆∞a t·ª´ th√°ng 5-10.",
            "best_time": "Th√°ng 3-5 v√† 9-11. Tr√°nh m√πa m∆∞a b√£o th√°ng 7-8.",
            "food": "ƒê·∫∑c s·∫£n n·ªïi ti·∫øng: Nem chua, b√°nh tr√¥i, b√°nh chay, c√° kho l√†ng V≈© ƒê·∫°i, c∆°m g√† ƒê√¥ng S∆°n.",
            "transport": "Di chuy·ªÉn b·∫±ng xe m√°y thu√™ ho·∫∑c taxi. N√™n c√≥ xe m√°y ƒë·ªÉ kh√°m ph√° c√°c b√£i bi·ªÉn.",
            "safety": "Thanh H√≥a kh√° an to√†n. N√™n mang ƒë·ªì b∆°i, kem ch·ªëng n·∫Øng v√† m≈© n√≥n khi ƒëi bi·ªÉn. Tr√°nh m√πa m∆∞a b√£o.",
            "souvenirs": "Nem chua Thanh H√≥a, b√°nh gai, ch√® lam, ƒë·ªì th·ªß c√¥ng m·ªπ ngh·ªá t·ª´ tre/g·ªó.",
            "notes": "N√™n ƒëi bi·ªÉn S·∫ßm S∆°n v√†o bu·ªïi s√°ng s·ªõm ho·∫∑c chi·ªÅu mu·ªôn. Mang theo kem ch·ªëng n·∫Øng SPF50+.",
        },
        "da-nang": {
            "weather": "ƒê√† N·∫µng c√≥ 2 m√πa r√µ r·ªát: Kh√¥ (2-8) v√† m∆∞a (9-1). Th·ªùi ti·∫øt t·ªët nh·∫•t t·ª´ th√°ng 3-5.",
            "best_time": "Th√°ng 3-8, ƒë·∫∑c bi·ªát th√°ng 4-6 th·ªùi ti·∫øt ƒë·∫πp nh·∫•t ƒë·ªÉ t·∫Øm bi·ªÉn.",
            "food": "ƒê·∫∑c s·∫£n: M√¨ Qu·∫£ng, b√°nh x√®o, b√∫n ch·∫£ c√°, b√°nh tr√°ng cu·ªën th·ªãt heo, nem l·ª•i.",
            "transport": "C√≥ xe bu√Ωt, grab, taxi. N√™n thu√™ xe m√°y ƒë·ªÉ t·ª± do kh√°m ph√°.",
            "safety": "An to√†n cao. N√™n c·∫©n th·∫≠n v·ªõi d√≤ng n∆∞·ªõc khi t·∫Øm bi·ªÉn, ƒë·∫∑c bi·ªát l√† M·ªπ Kh√™.",
            "souvenirs": "N∆∞·ªõc m·∫Øm Nam √î, m·ª±c m·ªôt n·∫Øng, b√°nh tr√°ng cu·ªën, ƒë·ªì l∆∞u ni·ªám B√† N√†, ƒë√° Non N∆∞·ªõc.",
            "notes": "Xem ph√°o hoa c·∫ßu R·ªìng t·ªëi th·ª© 7. ƒêi B√† N√† s√°ng s·ªõm tr√°nh ƒë√¥ng. Check th·ªùi ti·∫øt tr∆∞·ªõc khi l√™n S∆°n Tr√†.",
        },
        "ha-noi": {
            "weather": "H√† N·ªôi c√≥ 4 m√πa: Xu√¢n (2-4), h√® (5-8), thu (9-11), ƒë√¥ng (12-1). M√πa thu ƒë·∫πp nh·∫•t.",
            "best_time": "Th√°ng 9-11 (m√πa thu) v√† 3-4 (m√πa xu√¢n). Tr√°nh th√°ng 6-8 n√≥ng ·∫©m.",
            "food": "ƒê·∫∑c s·∫£n: Ph·ªü, b√∫n ch·∫£, b√°nh cu·ªën, ch·∫£ c√° L√£ V·ªçng, b√∫n ·ªëc.",
            "transport": "C√≥ xe bu√Ωs, grab, taxi. Ph·ªë c·ªï ƒëi b·ªô. Tr√°nh gi·ªù cao ƒëi·ªÉm.",
            "safety": "An to√†n nh∆∞ng c·∫©n th·∫≠n v·ªõi ƒë·ªì ƒë·∫°c ·ªü n∆°i ƒë√¥ng ng∆∞·ªùi. ƒê·ªôi m≈© b·∫£o hi·ªÉm khi ƒëi xe m√°y.",
            "souvenirs": "B√°nh c·ªëm, √¥ mai, tr√† sen T√¢y H·ªì, tranh ƒê√¥ng H·ªì, l·ª•a V·∫°n Ph√∫c, ƒë·ªì g·ªëm B√°t Tr√†ng.",
            "notes": "Ph·ªë c·ªï ƒëi b·ªô cu·ªëi tu·∫ßn. Th·ª≠ c√† ph√™ tr·ª©ng. ƒêi ch·ª£ ƒë√™m ph·ªë c·ªï t·ªëi th·ª© 6-CN.",
        },
        "ho-chi-minh": {
            "weather": "Kh√≠ h·∫≠u nhi·ªát ƒë·ªõi, 2 m√πa: Kh√¥ (12-4) v√† m∆∞a (5-11). N√≥ng quanh nƒÉm.",
            "best_time": "Th√°ng 12-4 (m√πa kh√¥). Th√°ng 1-2 c√≥ T·∫øt Nguy√™n ƒê√°n r·∫•t nh·ªôn nh·ªãp.",
            "food": "ƒê·∫∑c s·∫£n: B√°nh m√¨, h·ªß ti·∫øu, b√∫n b√≤ Hu·∫ø, c∆°m t·∫•m, b√°nh x√®o, g·ªèi cu·ªën.",
            "transport": "Grab, xe bu√Ωt, taxi. C·∫©n th·∫≠n giao th√¥ng ƒë√¥ng ƒë√∫c. N√™n d√πng Grab.",
            "safety": "C·∫©n th·∫≠n v·ªõi t√∫i x√°ch khi ƒëi xe m√°y. Gi·ªØ t√†i s·∫£n n∆°i ƒë√¥ng ng∆∞·ªùi.",
            "souvenirs": "C√† ph√™, b√°nh tr√°ng, m·ª©t, ƒë·ªì th·ªß c√¥ng Ch·ª£ B·∫øn Th√†nh, √°o d√†i.",
            "notes": "ƒêi ch·ª£ B·∫øn Th√†nh s√°ng s·ªõm. Bu·ªïi t·ªëi d·∫°o ph·ªë ƒëi b·ªô Nguy·ªÖn Hu·ªá. Th·ª≠ rooftop bar.",
        },
        "lam-dong": {
            "weather": "ƒê√† L·∫°t m√°t m·∫ª quanh nƒÉm 15-25¬∞C. M√πa m∆∞a 5-10, m√πa kh√¥ 11-4.",
            "best_time": "Th√°ng 11-3 (m√πa kh√¥, hoa n·ªü). Th√°ng 12-1 c√≥ hoa mai anh ƒë√†o.",
            "food": "ƒê·∫∑c s·∫£n: B√°nh tr√°ng n∆∞·ªõng, atiso, d√¢u t√¢y, c√† ph√™, rau c·ªß organic.",
            "transport": "Thu√™ xe m√°y ho·∫∑c ƒë·∫∑t tour. ƒê∆∞·ªùng ƒë√®o quanh co, c·∫©n th·∫≠n khi l√°i.",
            "safety": "An to√†n cao. Mang √°o ·∫•m v√¨ bu·ªïi t·ªëi l·∫°nh. C·∫©n th·∫≠n ƒë∆∞·ªùng ƒë√®o.",
            "souvenirs": "M·ª©t d√¢u, r∆∞·ª£u vang ƒê√† L·∫°t, atiso, c√† ph√™, hoa kh√¥, len handmade.",
            "notes": "Xem b√¨nh minh ƒë·ªìi ch√®. Ch·ª£ ƒë√™m s√¥i ƒë·ªông. Mang √°o kho√°c d√π m√πa h√®. ƒê·∫∑t ph√≤ng tr∆∞·ªõc d·ªãp l·ªÖ.",
        },
        "thua-thien-hue": {
            "weather": "Hu·∫ø m∆∞a nhi·ªÅu th√°ng 9-12. Kh√¥ r√°o th√°ng 2-7. N√≥ng th√°ng 5-8.",
            "best_time": "Th√°ng 2-4 th·ªùi ti·∫øt ƒë·∫πp nh·∫•t. Festival Hu·∫ø th∆∞·ªùng th√°ng 4 ho·∫∑c 6.",
            "food": "ƒê·∫∑c s·∫£n: B√∫n b√≤ Hu·∫ø, b√°nh b√®o, b√°nh n·∫≠m, c∆°m h·∫øn, m√® x·ª≠ng.",
            "transport": "Thu√™ xe ƒë·∫°p ho·∫∑c xe m√°y. ƒêi thuy·ªÅn s√¥ng H∆∞∆°ng r·∫•t th∆° m·ªông.",
            "safety": "An to√†n. C·∫©n th·∫≠n n·∫Øng n√≥ng m√πa h√®. Mang √¥/√°o m∆∞a m√πa m∆∞a.",
            "souvenirs": "M√® x·ª≠ng, n√≥n l√°, tr·∫ßm h∆∞∆°ng, tranh th√™u, √°o d√†i Hu·∫ø.",
            "notes": "M·∫∑c √°o d√†i ch·ª•p ·∫£nh ƒê·∫°i N·ªôi. Nghe ca Hu·∫ø tr√™n s√¥ng H∆∞∆°ng. ƒêi ch√πa Thi√™n M·ª• s√°ng s·ªõm.",
        },
        "quang-nam": {
            "weather": "H·ªôi An ·∫•m √°p. M√πa kh√¥ 2-8, m√πa m∆∞a 9-1. Tr√°nh th√°ng 10-11 hay l·ª•t.",
            "best_time": "Th√°ng 2-5 th·ªùi ti·∫øt ƒë·∫πp nh·∫•t. ƒê√™m 14 √¢m l·ªãch c√≥ ƒê√™m Ph·ªë C·ªï.",
            "food": "ƒê·∫∑c s·∫£n: Cao l·∫ßu, m√¨ Qu·∫£ng, b√°nh m√¨ Ph∆∞·ª£ng, c∆°m g√†, b√°nh bao b√°nh v·∫°c.",
            "transport": "Thu√™ xe ƒë·∫°p ho·∫∑c ƒëi b·ªô trong ph·ªë c·ªï. Grab ƒëi xa h∆°n.",
            "safety": "R·∫•t an to√†n. C·∫©n th·∫≠n th√°ng 10-11 hay ng·∫≠p l·ª•t.",
            "souvenirs": "ƒê√®n l·ªìng, l·ª•a, ƒë·ªì g·ªëm, tranh, may √°o d√†i theo y√™u c·∫ßu.",
            "notes": "D·∫°o ph·ªë c·ªï ƒë√™m ƒë·ªÉ ng·∫Øm ƒë√®n l·ªìng. Th·∫£ hoa ƒëƒÉng s√¥ng Ho√†i. May √°o d√†i trong ng√†y.",
        },
        "khanh-hoa": {
            "weather": "Nha Trang n·∫Øng ·∫•m quanh nƒÉm. M√πa m∆∞a ng·∫Øn 10-12.",
            "best_time": "Th√°ng 1-8 th·ªùi ti·∫øt ƒë·∫πp nh·∫•t ƒë·ªÉ t·∫Øm bi·ªÉn v√† l·∫∑n bi·ªÉn.",
            "food": "ƒê·∫∑c s·∫£n: B√∫n s·ª©a, b√°nh cƒÉn, nem n∆∞·ªõng, h·∫£i s·∫£n t∆∞∆°i s·ªëng.",
            "transport": "Grab, taxi, xe m√°y thu√™. ƒê·∫∑t tour ƒëi ƒë·∫£o ti·ªán l·ª£i.",
            "safety": "An to√†n. C·∫©n th·∫≠n gi·ªØ ƒë·ªì ·ªü b√£i bi·ªÉn. M·∫∑c √°o phao khi l·∫∑n bi·ªÉn.",
            "souvenirs": "Y·∫øn s√†o, tr·∫ßm h∆∞∆°ng, h·∫£i s·∫£n kh√¥, ƒë·ªì l∆∞u ni·ªám bi·ªÉn.",
            "notes": "ƒêi Vinpearl c·∫£ ng√†y. L·∫∑n bi·ªÉn ·ªü H√≤n Mun. Ng·∫Øm ho√†ng h√¥n B√£i D√†i.",
        },
        "default": {
            "weather": "Vi·ªát Nam c√≥ kh√≠ h·∫≠u nhi·ªát ƒë·ªõi gi√≥ m√πa. M√πa kh√¥ t·ªët cho du l·ªãch h∆°n m√πa m∆∞a.",
            "best_time": "Th√°ng 10-4 l√† m√πa du l·ªãch ch√≠nh. Tr√°nh m√πa m∆∞a b√£o th√°ng 7-9.",
            "food": "M·ªói v√πng mi·ªÅn c√≥ ƒë·∫∑c s·∫£n ri√™ng. N√™n th·ª≠ c√°c m√≥n ƒÉn ƒë∆∞·ªùng ph·ªë v√† ƒë·∫∑c s·∫£n ƒë·ªãa ph∆∞∆°ng.",
            "transport": "Grab, taxi, xe m√°y thu√™ l√† ph∆∞∆°ng ti·ªán ph·ªï bi·∫øn. N√™n book tr∆∞·ªõc ch·ªó ·ªü.",
            "safety": "Vi·ªát Nam an to√†n cho du l·ªãch. C·∫©n th·∫≠n v·ªõi t√†i s·∫£n, ƒë·ªôi m≈© b·∫£o hi·ªÉm khi ƒëi xe m√°y.",
            "souvenirs": "C√† ph√™, n√≥n l√°, √°o d√†i, ƒë·ªì th·ªß c√¥ng m·ªπ ngh·ªá, ƒë·∫∑c s·∫£n ƒë·ªãa ph∆∞∆°ng.",
            "notes": "Mang theo kem ch·ªëng n·∫Øng, n√≥n, k√≠nh r√¢m. Book tr∆∞·ªõc kh√°ch s·∫°n d·ªãp l·ªÖ.",
        },
    }

    def __init__(self, mongo_manager=None, llm_client=None):
        self.mongo = mongo_manager
        self.llm = llm_client

        # Initialize entity extractor for precise context-based queries
        self.entity_extractor = create_entity_extractor(
            llm_client=llm_client, mongo_manager=mongo_manager
        )

        logger.info("‚úÖ GeneralInfoExpert initialized (with Entity Extractor)")

    @property
    def expert_type(self) -> str:
        return "general_info"

    def execute(self, query: str, parameters: Dict[str, Any]) -> ExpertResult:
        """
        Answer general questions about destination

        Parameters:
            - location: Province/city name
            - context: Additional context from conversation
            - original_query: Original user question
        """
        start_time = time.time()

        try:
            location = parameters.get("location", "")
            original_query = parameters.get("original_query", query)
            context = parameters.get("context", {})  # Get full conversation context

            # Normalize location
            province_id = self._normalize_location(location)

            logger.info(
                f"üîç GeneralInfoExpert: query='{query}', original='{original_query[:50]}...', location={province_id}"
            )

            # Extract entities from query using context
            extracted_entities = self.entity_extractor.extract_entities(
                original_query, context
            )

            logger.info(
                f"üìä Extracted: {len(extracted_entities['spots'])} spots, {len(extracted_entities['hotels'])} hotels"
            )

            # Gather relevant data from database (with entity filtering)
            context_data = self._gather_context_data(
                province_id,
                original_query,
                extracted_entities,  # Pass extracted entities for precise query
            )

            # Use LLM to generate answer based on context
            if self.llm and context_data:
                answer = self._generate_llm_answer(
                    original_query, location, context_data
                )
            else:
                # Fallback to template-based tips
                tips = self._get_relevant_tips(original_query, province_id)
                answer = "\n\n".join(tips)

            # Build response
            response_data = [
                {
                    "type": "info",
                    "location": location,
                    "answer": answer,
                    "query": original_query,
                }
            ]

            execution_time = int((time.time() - start_time) * 1000)

            # Generate summary for reply
            summary = answer if answer else self._generate_fallback_summary(location)

            return ExpertResult(
                expert_type=self.expert_type,
                success=True,
                data=response_data,
                summary=summary,
                execution_time_ms=execution_time,
            )

        except Exception as e:
            logger.error(f"‚ùå GeneralInfoExpert error: {e}")
            import traceback

            traceback.print_exc()
            return ExpertResult(
                expert_type=self.expert_type,
                success=False,
                data=[],
                summary="",
                error=str(e),
                execution_time_ms=int((time.time() - start_time) * 1000),
            )

    def _gather_context_data(
        self,
        province_id: str,
        query: str,
        entities: Dict[str, List[ExtractedEntity]] = None,
    ) -> Dict[str, Any]:
        """
        Gather relevant data from database based on query.
        NEW: Uses extracted entities for precise filtering (accuracy boost 20% ‚Üí 95%)
        ENHANCED: Cross-province search for "X ·ªü ƒë√¢u" queries
        """
        context = {
            "spots": [],
            "hotels": [],
            "food_info": [],
            "province_info": {},
            "cross_province_results": [],  # NEW: For "X ·ªü ƒë√¢u" queries
        }

        if not self.mongo:
            return context

        try:
            query_lower = query.lower()

            # Get province information
            provinces_col = self.mongo.get_collection("provinces_info")
            if provinces_col is not None:
                province_doc = provinces_col.find_one({"province_id": province_id})
                if province_doc:
                    context["province_info"] = {
                        "name": province_doc.get("name", ""),
                        "description": province_doc.get("description", ""),
                        "highlights": province_doc.get("highlights", []),
                    }

            # ENHANCED: Detect "X ·ªü ƒë√¢u" pattern - search across ALL provinces
            is_location_query = any(
                pattern in query_lower
                for pattern in ["·ªü ƒë√¢u", "·ªü n∆°i n√†o", "t·∫°i ƒë√¢u", "where is", "thu·ªôc"]
            )

            # Get spots data - NEW: Use entity-based query for precision
            if entities and entities.get("spots"):
                # HIGH PRECISION: Query by specific entity names
                spots_col = self.mongo.get_collection("spots_detailed")
                if spots_col is not None:
                    for spot_entity in entities["spots"]:
                        if is_location_query:
                            # CROSS-PROVINCE SEARCH: Find ALL matching spots nationwide
                            all_spots = list(
                                spots_col.find(
                                    {
                                        "name": {
                                            "$regex": spot_entity.name,
                                            "$options": "i",
                                        }
                                    }
                                ).limit(20)
                            )  # Limit to prevent overload

                            if all_spots:
                                logger.info(
                                    f"üåç Cross-province search: Found {len(all_spots)} matches for '{spot_entity.name}'"
                                )
                                for spot in all_spots:
                                    # Get province name for this spot
                                    spot_province = spot.get("province_id", "")
                                    province_name = spot.get(
                                        "province_name", spot_province
                                    )

                                    # If no province_name in spot, look it up
                                    if not province_name and provinces_col:
                                        prov_doc = provinces_col.find_one(
                                            {"province_id": spot_province}
                                        )
                                        province_name = (
                                            prov_doc.get("name", spot_province)
                                            if prov_doc
                                            else spot_province
                                        )

                                    context["cross_province_results"].append(
                                        {
                                            "name": spot.get("name"),
                                            "province": province_name,
                                            "province_id": spot_province,
                                            "description": spot.get(
                                                "description_short", ""
                                            ),
                                            "rating": spot.get("rating"),
                                            "cost": spot.get("cost", ""),
                                            "address": spot.get("address", ""),
                                            "confidence": spot_entity.confidence,
                                        }
                                    )
                            else:
                                logger.info(
                                    f"‚ö†Ô∏è No cross-province matches for '{spot_entity.name}'"
                                )
                        else:
                            # NORMAL: Search within current province only
                            spot = spots_col.find_one(
                                {
                                    "name": {
                                        "$regex": spot_entity.name,
                                        "$options": "i",
                                    },
                                    "province_id": province_id,
                                }
                            )

                            if spot:
                                context["spots"].append(
                                    {
                                        "name": spot.get("name"),
                                        "description": spot.get(
                                            "description_short", ""
                                        ),
                                        "rating": spot.get("rating"),
                                        "cost": spot.get("cost", ""),
                                        "tags": spot.get("tags", []),
                                        "confidence": spot_entity.confidence,
                                    }
                                )
                                logger.info(
                                    f"‚úÖ Precise query: Found '{spot.get('name')}' (confidence: {spot_entity.confidence})"
                                )

            # Fallback: Broad search if no entities found
            elif any(
                word in query_lower
                for word in [
                    "ƒë·ªãa ƒëi·ªÉm",
                    "ch·ªó",
                    "tham quan",
                    "ch∆°i",
                    "ƒëi",
                    "visit",
                    "l∆∞u √Ω",
                    "c·∫©n th·∫≠n",
                    "ƒë·ªÅ ph√≤ng",
                ]
            ):
                spots_col = self.mongo.get_collection("spots_detailed")
                if spots_col is not None:
                    # Get top rated spots with descriptions
                    spots = (
                        spots_col.find({"province_id": province_id})
                        .sort("rating", -1)
                        .limit(10)
                    )

                    for spot in spots:
                        context["spots"].append(
                            {
                                "name": spot.get("name"),
                                "description": spot.get("description_short", ""),
                                "rating": spot.get("rating"),
                                "cost": spot.get("cost", ""),
                                "tags": spot.get("tags", []),
                                "confidence": 0.2,  # Low confidence - broad search
                            }
                        )

            # Get hotel data - NEW: Use entity-based query
            if entities and entities.get("hotels"):
                hotels_col = self.mongo.get_collection("hotels")
                if hotels_col is not None:
                    for hotel_entity in entities["hotels"]:
                        # Try exact match first
                        hotel = hotels_col.find_one(
                            {
                                "name": {"$regex": hotel_entity.name, "$options": "i"},
                                "province_id": province_id,
                            }
                        )

                        # If no match, try partial match with first significant word
                        if not hotel:
                            words = hotel_entity.name.split()
                            for word in words:
                                if len(word) > 3:  # Skip short words
                                    hotel = hotels_col.find_one(
                                        {
                                            "name": {"$regex": word, "$options": "i"},
                                            "province_id": province_id,
                                        }
                                    )
                                    if hotel:
                                        break

                        if hotel:
                            context["hotels"].append(
                                {
                                    "name": hotel.get("name"),
                                    "rating": hotel.get("rating"),
                                    "price": hotel.get("price"),
                                    "amenities": hotel.get("amenities", []),
                                    "confidence": hotel_entity.confidence,
                                }
                            )
                            logger.info(
                                f"‚úÖ Precise query: Found '{hotel.get('name')}' (confidence: {hotel_entity.confidence})"
                            )

            # Fallback: Broad hotel search
            elif any(
                word in query_lower
                for word in ["kh√°ch s·∫°n", "hotel", "·ªü", "ngh·ªâ", "ng·ªß", "gi√°", "ti·ªÅn"]
            ):
                hotels_col = self.mongo.get_collection("hotels")
                if hotels_col is not None:
                    hotels = (
                        hotels_col.find({"province_id": province_id})
                        .sort("rating", -1)
                        .limit(5)
                    )

                    for hotel in hotels:
                        context["hotels"].append(
                            {
                                "name": hotel.get("name"),
                                "rating": hotel.get("rating"),
                                "price": hotel.get("price"),
                                "confidence": 0.2,  # Low confidence - broad search
                            }
                        )

            logger.info(
                f"üìä Gathered context: {len(context['spots'])} spots, {len(context['hotels'])} hotels"
            )

        except Exception as e:
            logger.error(f"‚ùå Error gathering context: {e}")

        return context

    def _generate_llm_answer(
        self, query: str, location: str, context_data: Dict
    ) -> str:
        """Use LLM to generate natural answer based on context"""
        try:
            # Build context summary
            context_parts = []

            # PRIORITY: Cross-province results (for "X ·ªü ƒë√¢u" queries)
            if context_data.get("cross_province_results"):
                results = context_data["cross_province_results"]
                logger.info(f"üìç Using {len(results)} cross-province results")

                locations_text = []
                for result in results[:10]:  # Limit to top 10
                    loc_desc = f"- **{result['name']}** t·∫°i {result['province']}"
                    if result.get("address"):
                        loc_desc += f" ({result['address']})"
                    if result.get("description"):
                        loc_desc += f"\n  {result['description'][:100]}"
                    locations_text.append(loc_desc)

                context_parts.append(
                    f"C√°c ƒë·ªãa ƒëi·ªÉm t√¨m th·∫•y:\n" + "\n".join(locations_text)
                )

            if context_data.get("province_info"):
                info = context_data["province_info"]
                if info.get("description"):
                    context_parts.append(
                        f"Th√¥ng tin chung v·ªÅ {location}: {info['description']}"
                    )

            if context_data.get("spots"):
                spots_text = []
                for spot in context_data["spots"][:5]:
                    spot_desc = f"- {spot['name']}"
                    if spot.get("description"):
                        spot_desc += f": {spot['description'][:100]}"
                    if spot.get("cost"):
                        spot_desc += f" (Chi ph√≠: {spot['cost']})"
                    spots_text.append(spot_desc)
                context_parts.append(f"C√°c ƒë·ªãa ƒëi·ªÉm n·ªïi b·∫≠t:\n" + "\n".join(spots_text))

            if context_data.get("hotels") and len(context_data["hotels"]) > 0:
                avg_price = sum(
                    h.get("price", 0) for h in context_data["hotels"]
                ) / len(context_data["hotels"])
                context_parts.append(
                    f"Gi√° kh√°ch s·∫°n trung b√¨nh: {int(avg_price):,} VNƒê/ƒë√™m"
                )

            # Add hardcoded tips for safety questions
            query_lower = query.lower()
            if any(
                word in query_lower
                for word in ["l∆∞u √Ω", "c·∫©n th·∫≠n", "ƒë·ªÅ ph√≤ng", "chu·∫©n b·ªã", "safety"]
            ):
                province_id = self._normalize_location(location)
                tips = self.TRAVEL_TIPS.get(province_id, self.TRAVEL_TIPS["default"])
                context_parts.append(f"L∆∞u √Ω khi du l·ªãch: {tips['safety']}")
                if tips.get("weather"):
                    context_parts.append(f"Th·ªùi ti·∫øt: {tips['weather']}")

            context_text = "\n\n".join(context_parts)

            # Detect if this is a location query
            is_location_query = any(
                pattern in query_lower
                for pattern in ["·ªü ƒë√¢u", "·ªü n∆°i n√†o", "t·∫°i ƒë√¢u", "where is", "thu·ªôc"]
            )

            # Build prompt with different instructions for location queries
            if is_location_query and context_data.get("cross_province_results"):
                prompt = f"""B·∫°n l√† tr·ª£ l√Ω du l·ªãch chuy√™n nghi·ªáp. Kh√°ch h√†ng ƒëang h·ªèi v·ªÅ v·ªã tr√≠ c·ªßa m·ªôt ƒë·ªãa danh. D·ª±a tr√™n k·∫øt qu·∫£ t√¨m ki·∫øm, h√£y tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c.

K·∫æT QU·∫¢ T√åM KI·∫æM:
{context_text}

C√ÇU H·ªéI: {query}

Y√™u c·∫ßu:
- Li·ªát k√™ T·∫§T C·∫¢ c√°c ƒë·ªãa ƒëi·ªÉm t√¨m th·∫•y v·ªõi t√™n v√† t·ªânh/th√†nh ph·ªë
- S·∫Øp x·∫øp theo m·ª©c ƒë·ªô n·ªïi ti·∫øng (rating cao, m√¥ t·∫£ chi ti·∫øt h∆°n)
- N·∫øu c√≥ nhi·ªÅu k·∫øt qu·∫£: "C√≥ nhi·ªÅu ƒë·ªãa ƒëi·ªÉm t√™n X, bao g·ªìm:"
- N·∫øu kh√¥ng t√¨m th·∫•y trong context hi·ªán t·∫°i nh∆∞ng c√≥ context v·ªÅ {location}: n√≥i r√µ "X kh√¥ng c√≥ trong {location}, nh∆∞ng c√≥ th·ªÉ t√¨m th·∫•y ·ªü..."
- Th√™m emoji ph√π h·ª£p
- Ng·∫Øn g·ªçn, s√∫c t√≠ch (4-6 d√≤ng)
- Kh√¥ng ƒë·ªÅ c·∫≠p "d·ª±a tr√™n th√¥ng tin" hay "theo d·ªØ li·ªáu"

TR·∫¢ L·ªúI:"""
            else:
                prompt = f"""B·∫°n l√† tr·ª£ l√Ω du l·ªãch chuy√™n nghi·ªáp. D·ª±a tr√™n th√¥ng tin sau v·ªÅ {location}, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch du l·ªãch m·ªôt c√°ch t·ª± nhi√™n, h·ªØu √≠ch v√† th√¢n thi·ªán.

TH√îNG TIN V·ªÄ {location.upper()}:
{context_text}

C√ÇU H·ªéI: {query}

Y√™u c·∫ßu:
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch (3-5 c√¢u)
- S·ª≠ d·ª•ng emoji ph√π h·ª£p
- ƒê∆∞a ra l·ªùi khuy√™n th·ª±c t·∫ø d·ª±a tr√™n th√¥ng tin c√≥
- N·∫øu h·ªèi v·ªÅ m√≥n ƒÉn: li·ªát k√™ c√°c ƒë·∫∑c s·∫£n
- N·∫øu h·ªèi v·ªÅ l∆∞u √Ω/ƒë·ªÅ ph√≤ng: ƒë∆∞a ra c√°c tips an to√†n, th·ªùi ti·∫øt, chu·∫©n b·ªã
- N·∫øu h·ªèi v·ªÅ ƒë·ªãa ƒëi·ªÉm: g·ª£i √Ω 2-3 ƒëi·ªÉm n·ªïi b·∫≠t
- Kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác "d·ª±a tr√™n th√¥ng tin" hay "theo d·ªØ li·ªáu"

TR·∫¢ L·ªúI:"""

            # Call LLM using complete method
            response = self.llm.complete(prompt=prompt, max_tokens=300, temperature=0.7)

            answer = response.strip()

            # Clean up common LLM artifacts
            if answer.startswith("TR·∫¢ L·ªúI:"):
                answer = answer[8:].strip()

            logger.info(f"‚úÖ LLM generated answer: {answer[:100]}...")
            return answer

        except Exception as e:
            logger.error(f"‚ùå LLM generation failed: {e}")
            # Fallback to template
            return self._generate_fallback_summary(location)

    def _generate_fallback_summary(self, location: str) -> str:
        """Generate fallback summary when LLM fails"""
        return f"‚ÑπÔ∏è ƒê·ªÉ m√¨nh t√¨m hi·ªÉu th√™m th√¥ng tin v·ªÅ {location} v√† tr·∫£ l·ªùi b·∫°n nh√©!"

    def _get_relevant_tips(self, query: str, province_id: str) -> List[str]:
        """Get relevant travel tips based on query"""
        query_lower = query.lower()
        tips = []

        # Get province-specific tips or default
        province_tips = self.TRAVEL_TIPS.get(province_id, self.TRAVEL_TIPS["default"])

        # Match query with tip categories
        if any(
            word in query_lower
            for word in ["th·ªùi ti·∫øt", "kh√≠ h·∫≠u", "weather", "m∆∞a", "n·∫Øng"]
        ):
            tips.append(f"üå§Ô∏è **Th·ªùi ti·∫øt:** {province_tips['weather']}")

        if any(
            word in query_lower
            for word in ["th·ªùi gian", "khi n√†o", "th√°ng", "m√πa", "best time", "n√™n ƒëi"]
        ):
            tips.append(
                f"üìÖ **Th·ªùi gian ƒë·∫πp nh·∫•t:** {province_tips.get('best_time', province_tips['weather'])}"
            )

        if any(
            word in query_lower
            for word in ["ƒÉn", "m√≥n", "food", "ƒë·∫∑c s·∫£n", "qu√°n", "nh√† h√†ng"]
        ):
            tips.append(f"üçú **·∫®m th·ª±c:** {province_tips['food']}")

        if any(
            word in query_lower
            for word in ["di chuy·ªÉn", "ph∆∞∆°ng ti·ªán", "transport", "xe", "taxi", "grab"]
        ):
            tips.append(f"üöó **Di chuy·ªÉn:** {province_tips['transport']}")

        if any(
            word in query_lower
            for word in [
                "an to√†n",
                "l∆∞u √Ω",
                "c·∫©n th·∫≠n",
                "ƒë·ªÅ ph√≤ng",
                "safety",
                "chu·∫©n b·ªã",
                "note",
            ]
        ):
            tips.append(f"‚ö†Ô∏è **L∆∞u √Ω:** {province_tips['safety']}")
            if province_tips.get("notes"):
                tips.append(f"üí° **M·∫πo:** {province_tips['notes']}")

        if any(
            word in query_lower
            for word in [
                "l∆∞u ni·ªám",
                "qu√†",
                "mua g√¨",
                "souvenir",
                "ƒë·∫∑c s·∫£n mua",
                "v·ªÅ l√†m qu√†",
            ]
        ):
            if province_tips.get("souvenirs"):
                tips.append(f"üéÅ **ƒê·ªì l∆∞u ni·ªám:** {province_tips['souvenirs']}")

        # If no specific match, provide overview tips
        if not tips:
            tips = [
                f"üìÖ **Th·ªùi gian ƒë·∫πp nh·∫•t:** {province_tips.get('best_time', 'Quanh nƒÉm')}",
                f"üçú **·∫®m th·ª±c:** {province_tips['food']}",
                f"üöó **Di chuy·ªÉn:** {province_tips['transport']}",
                f"‚ö†Ô∏è **L∆∞u √Ω:** {province_tips['safety']}",
            ]
            if province_tips.get("souvenirs"):
                tips.append(f"üéÅ **ƒê·ªì l∆∞u ni·ªám:** {province_tips['souvenirs']}")
            if province_tips.get("notes"):
                tips.append(f"üí° **M·∫πo:** {province_tips['notes']}")

        return tips

    def _generate_summary(self, tips: List[str], location: str, query: str) -> str:
        """Generate summary for conversation reply"""
        if not tips:
            return f"‚ÑπÔ∏è Xin l·ªói, m√¨nh ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ v·∫•n ƒë·ªÅ n√†y ·ªü {location}."

        lines = [f"‚ÑπÔ∏è **Th√¥ng tin v·ªÅ {location}**\n"]
        lines.extend(tips)

        return "\n".join(lines)

    def _normalize_location(self, location: str) -> str:
        """Normalize location name to province_id"""
        if not location:
            return "default"

        location_lower = location.lower().strip()

        # Common normalizations - map to province_id keys in TRAVEL_TIPS
        mapping = {
            "ƒë√† n·∫µng": "da-nang",
            "da nang": "da-nang",
            "thanh h√≥a": "thanh-hoa",
            "thanh hoa": "thanh-hoa",
            "h√† n·ªôi": "ha-noi",
            "ha noi": "ha-noi",
            "hanoi": "ha-noi",
            "s√†i g√≤n": "ho-chi-minh",
            "saigon": "ho-chi-minh",
            "h·ªì ch√≠ minh": "ho-chi-minh",
            "ho chi minh": "ho-chi-minh",
            "hcm": "ho-chi-minh",
            "ph√∫ qu·ªëc": "kien-giang",
            "phu quoc": "kien-giang",
            "ƒë√† l·∫°t": "lam-dong",
            "da lat": "lam-dong",
            "dalat": "lam-dong",
            "l√¢m ƒë·ªìng": "lam-dong",
            "hu·∫ø": "thua-thien-hue",
            "hue": "thua-thien-hue",
            "th·ª´a thi√™n hu·∫ø": "thua-thien-hue",
            "h·ªôi an": "quang-nam",
            "hoi an": "quang-nam",
            "qu·∫£ng nam": "quang-nam",
            "nha trang": "khanh-hoa",
            "kh√°nh h√≤a": "khanh-hoa",
            "khanh hoa": "khanh-hoa",
            "sapa": "lao-cai",
            "sa pa": "lao-cai",
            "l√†o cai": "lao-cai",
        }

        return mapping.get(location_lower, location_lower.replace(" ", "-"))
